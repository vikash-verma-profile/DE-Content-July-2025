questionTitle,questionType,questionDescription,correctOptionNumbers,positiveMarks,negativeMarks,questionAnswerExplanation,questionOption1,questionOption2,questionOption3,questionOption4
Question 1,single-correct,What is the primary role of a control table in data orchestration?,3,1,0,A control table stores metadata like source paths, load status, or watermarks for driving pipeline logic.,Store credentials,Manage triggers,Drive dynamic pipeline behavior using metadata,Host source datasets
Question 2,single-correct,What must a control table typically include to implement a watermark-based pattern?,2,1,0,A column like `last_loaded_timestamp` helps track incremental loads.,Primary key only,Watermark column (e.g., last_loaded_timestamp),Static parameters,Linked service metadata
Question 3,single-correct,How does a dynamic dataset reference improve ADF pipeline reusability?,1,1,0,Dynamic datasets allow parameterization of file names, paths, or formats at runtime.,Supports parameterized path/schema for reuse,Executes lookup queries automatically,Runs only in debug mode,Applies only to sink datasets
Question 4,single-correct,In a pipeline, what is the purpose of using a Lookup activity before a ForEach loop?,3,1,0,Lookup is used to retrieve a list of items over which the ForEach can iterate.,Log execution status,Send email alerts,Provide iterable values to ForEach loop,Reduce dataset size
Question 5,single-correct,Which scenario best fits the use of a Watermark Resume pattern?,2,1,0,It is ideal for incremental loads where only new/changed data is ingested.,Export full datasets,Incremental ingestion based on timestamps,Schema inference from files,Delta Lake versioning
Question 6,single-correct,Where is the watermark value typically updated after successful pipeline execution?,1,1,0,Watermark is updated back in the control table to reflect the latest state.,In control table or metadata store,In sink dataset,In data preview logs,In linked service headers
Question 7,single-correct,What format is commonly used for orchestration logging in modern Lakehouse architecture?,4,1,0,Delta format enables efficient storage, querying, and time travel of orchestration logs.,Parquet only,CSV only,Raw JSON,Delta Lake format
Question 8,single-correct,What is a key benefit of logging pipeline execution results into a Delta table?,3,1,0,Delta tables support historical tracking, ACID transactions, and efficient queries.,Cheaper storage,Less compute required,Supports audit trail and historical analysis,Reduces trigger frequency
Question 9,single-correct,What is the primary function of a restart script in a robust data pipeline setup?,1,1,0,A restart script helps re-initiate failed pipelines or load states from the last known good point.,Resumes pipeline from last failed checkpoint,Schedules triggers only,Manages Git branches,Deletes staging files
Question 10,single-correct,In a restart script demo, which component typically determines what data to reprocess?,2,1,0,Watermark values stored in control tables are read to decide the reprocessing range.,Activity count,Control-table watermark values,Integration Runtime type,Blob container ACLs
